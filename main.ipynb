{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsdGUjmfWw6KWEcgn0iytG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/motabha1/NLP-Homework/blob/assignment-1/NLP_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO_hbVG4WJ9-"
      },
      "source": [
        "**Phrase Extraction from a paragraph**\n",
        "\n",
        "The approach here is dividied into two steps:\n",
        "\n",
        "\n",
        "1.   For each sentence of the paragraph, we will find its corresponding parse tree\n",
        "2.   The resulting leaves of subtrees with labels Verb Phrase (VP), Noun Phrase(NP) and Prepositional Phrase (PP) will give us the phrases we require\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GChFaRmbrw5q"
      },
      "source": [
        "# Part of Stanford NLP \n",
        "\n",
        "!pip install stanza"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-33oBeUpHMK4"
      },
      "source": [
        "# Here we will be Stanford Core NLP client for creating a parse tree\n",
        "# To use it in google colab we will have to start a background Java Core NLP process and initialize a client in Python\n",
        "# This client will be further used to generate annotated result from text input\n",
        "\n",
        "from nltk import Tree\n",
        "import stanza\n",
        "from stanza.server import CoreNLPClient\n",
        "import time\n",
        "\n",
        "stanza.install_corenlp()\n",
        "\n",
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\n",
        "client = CoreNLPClient(\n",
        "    annotators=['tokenize','ssplit', 'pos', 'lemma', 'ner'], \n",
        "    memory='4G', \n",
        "    endpoint='http://localhost:9001',\n",
        "    be_quiet=True)\n",
        "print(client)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sONHAY9ZOuQo"
      },
      "source": [
        "# This is the runner method for our homework problem\n",
        "# Here we will take a paragraph as input, the resulting phrases extracted from the paragraph are stored in the \"phrases\" list \n",
        "\n",
        "\n",
        "\n",
        "# This method will return the parse trees for paragraph\n",
        "# First the paragraph is broken into sentences and then a parse tree is made for each of the resulting sentence and added to the trees list\n",
        "# From each of the tree (obtained from sentence), we will be generating phrases\n",
        "def getParseTrees(txt):\n",
        "  trees = []\n",
        "  output = client.annotate(txt, properties={\n",
        "      'annotators': 'parse',\n",
        "      'outputFormat': 'json'\n",
        "    })\n",
        "  for sent in output['sentences']:\n",
        "    tree = Tree.fromstring(sent['parse'])\n",
        "    trees.append(tree)\n",
        "  return trees \n",
        "\n",
        "\n",
        "\n",
        "# This is the main method that extract information from the parse trees\n",
        "# Here the parse tree and label are passed as arguments\n",
        "# Our code will look for each of the subtrees and extract terminal nodes of those subtrees which have the required labels\n",
        "# The leaves are then joined and made into a string which is our required phrase\n",
        "def getPhrases(tree, pt):\n",
        "  phrases = []\n",
        "  for subtree in tree.subtrees():\n",
        "    if(subtree.label() == pt and type(subtree) == Tree):\n",
        "      phrases.append(' '.join(subtree.leaves()))\n",
        "  return phrases\n",
        "\n",
        "\n",
        "text = input()\n",
        "\n",
        "phrases = []\n",
        "trees = getParseTrees(text)\n",
        "\n",
        "# These are the type of labels that CoreNLPClient will generate in a parse tree\n",
        "phraseTypes = [\"NP\", \"VP\", \"PP\"]\n",
        "\n",
        "# For each tree (sentence) we will find a phrase and append to our main list\n",
        "for tree in trees:\n",
        "  for pt in phraseTypes:\n",
        "    phrases = phrases + getPhrases(tree, pt)\n",
        "\n",
        "for phrase in phrases:\n",
        "  print(phrase)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
